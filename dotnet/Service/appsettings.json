{
  "SemanticMemory": {
    // =====================
    // ====== Service ======
    // =====================
    "Service": {
      // Whether to run the web service that allows to upload files and search memory
      // Use these booleans to deploy the web service and the handlers on same/different VMs
      "RunWebService": true,
      // Whether to run the asynchronous pipeline handlers
      // Use these booleans to deploy the web service and the handlers on same/different VMs
      "RunHandlers": true,
    },
    // =====================
    // =====================
    // ====== Search =======
    // =====================
    "Search": {
      // Which vector storage to use when searching for embeddings
      // Note: Within a DB, each user's data is stored in a separate index. The index name
      //       has a configurable prefix. Most Vector DBs don't allow to mix vectors of
      //       different dimensions, and will throw exceptions if the scenario is detected.
      //       Also, vectors with the same dimension from different providers or different
      //       LLM versions should not be mixed in the same index. In such case you
      //       should use different prefixes, to differentiate between models/versions.
      "VectorDb": {
        // "Type": "AzureCognitiveSearch" or "Qdrant",
        //
        // For Azure Cognitive Search:
        //   "Type": "AzureCognitiveSearch",
        //   "Endpoint": "https://<...>",
        //   "APIKey": "",
        //   "VectorIndexPrefix": "smemory-",
        //
        // For Qdrant:
        //   "Type": "Qdrant",
        //   "Endpoint": "https://<...>",
        //   "APIKey": "",
        //   "VectorIndexPrefix": "smemory-",
      },
      // Which embedding generator to use to:
      // - generate embedding for the give questions
      // - identify the name of the index to search (indexes have a specific name and vector size)
      "EmbeddingGenerator": {
        // "Type": "AzureOpenAI" or "OpenAI", // This value is used also to locate the correct index names in the Vector DB
        //
        // For Azure OpenAI:
        //   "Type": "AzureOpenAI",
        //   "Endpoint": "https://<...>.openai.azure.com/",
        //   "Deployment": "", // This value is used also to locate the correct index names in the Vector DB
        //   "APIKey": "",
        //
        // For OpenAI:
        //   "Type": "OpenAI",
        //   "Model": "text-embedding-ada-002", // This value is used also to locate the correct index names in the Vector DB
        //   "APIKey": "",
        //   "OrgId": "",
      },
      // Which LLM to use to run prompts and generate answers, e.g. gpt-4, gpt-3.5-turbo-16k, etc.
      "TextGenerator": {
        // "Type": "AzureOpenAI" or "OpenAI",
        //
        // For Azure OpenAI:
        //   "Type": "AzureOpenAI",
        //   "Endpoint": "https://<...>.openai.azure.com/",
        //   "Deployment": "",
        //   "APIKey": "",
        //
        // For OpenAI:
        //   "Type": "OpenAI",
        //   "Model": "text-embedding-ada-002",
        //   "APIKey": "",
        //   "OrgId": "",
      }
    },
    // =====================
    // ====== Content ======
    // =====================
    "ContentStorage": {
      // - FileSystem: store files locally on disk
      // - AzureBlobs: store files in Azure Storage Blobs
      "Type": "FileSystem",
      "FileSystem": {
        "Directory": "/tmp/semanticmemory/content"
      },
      "AzureBlobs": {
        // - AzureIdentity: use automatic AAD authentication mechanism. You can test this locally
        //   using the env vars AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET.
        // - ConnectionString: auth using a connection string
        "Auth": "AzureIdentity",
        // Azure Storage account name, required when using AzureIdentity auth
        // Note: you can use an env var 'SemanticMemory__ContentStorage__AzureBlobs__Account' to set this
        "Account": "",
        // Container where to create directories and upload files
        "Container": "",
        // Required when Auth == ConnectionString
        // Note: you can use an env var 'SemanticMemory__ContentStorage__AzureBlobs__ConnectionString' to set this
        "ConnectionString": "",
        // Setting used only for country clouds
        "EndpointSuffix": "core.windows.net"
      }
    },
    // ===========================
    // ====== Orchestration ======
    // ===========================
    "Orchestration": {
      // - InProcess: in process .NET orchestrator, synchronous/no queues
      // - Distributed: asynchronous queue based orchestrator
      "Type": "InProcess",
      // Used when Type == Distributed
      "DistributedPipeline": {
        // - AzureQueue: orchestrate pipelines progress using Azure queues
        // - RabbitMQ: orchestrate pipelines progress using RabbitMQ queues
        // - FileBasedQueue: orchestrate pipelines progress using simple file-based queues
        "Type": "AzureQueue",
        // Used when Type == AzureQueue
        "AzureQueue": {
          // - AzureIdentity: use automatic AAD authentication mechanism
          // - ConnectionString: auth using a connection string
          "Auth": "AzureIdentity",
          // Azure Storage account name, required when using AzureIdentity auth
          // Note: you can use an env var 'SemanticMemory__Orchestration__DistributedPipeline__AzureQueue__Account' to set this
          "Account": "",
          // Required when Auth == ConnectionString
          // Note: you can use an env var 'SemanticMemory__Orchestration__DistributedPipeline__AzureQueue__ConnectionString' to set this
          "ConnectionString": "",
          // Setting used only for country clouds
          "EndpointSuffix": "core.windows.net"
        },
        // Used when Type == RabbitMQ
        "RabbitMq": {
          "Host": "127.0.0.1",
          "Port": "5672",
          "Username": "user",
          "Password": ""
        },
        // Used when Type == FileBasedQueue
        "FileBasedQueue": {
          "Path": "/tmp/semanticmemory/queues"
        },
      },
    },
    // ===============================
    // ====== Pipeline Handlers ======
    // ===============================
    "Handlers": {
      "extract": {
        // Custom key-values
      },
      "partition": {
        // Custom key-values
      },
      "gen_embeddings": {
        // Which generators to use, for each text partition/chunk. Normally only one generator is active.
        // Having multiple active generators allows to create more advanced setups e.g. comparing embedding
        // types, combining searches, etc. Currently only one value is supported.
        "EmbeddingGenerators": [
          // {
          //   "Type": "AzureOpenAI",
          //   "Endpoint": "https://<...>.openai.azure.com/",
          //   "Deployment": "",
          //   "APIKey": "",
          // },
          // {
          //   "Type": "OpenAI",
          //   "Model": "text-embedding-ada-002",
          //   "APIKey": "",
          //   "OrgId": "",
          // },
          // {
          //   Not supported yet
          //   "Type": "SentenceTransformers",
          //   "Model": "all-MiniLM-L6-v2",
          // },
        ],
      },
      "save_embeddings": {
        "VectorDbs": [
          // Note: embeddings can be stored in multiple DBs at the same time.
          //       Within a DB, each user's data is stored in a separate index. The index name
          //       has a configurable prefix. Most Vector DBs don't allow to mix vectors of
          //       different dimensions, and will throw exceptions if the scenario is detected.
          //       Also, vectors with the same dimension from different providers or different
          //       LLM versions should not be mixed in the same index. In such case you
          //       should use different prefixes, to differentiate between models/versions.
          // {
          //   "Type": "AzureCognitiveSearch",
          //   "Endpoint": "https://<...>",
          //   "APIKey": "",
          //   "VectorIndexPrefix": "smemory-",
          // },
          // {
          //   "Type": "Qdrant",
          //   "Endpoint": "https://<...>",
          //   "APIKey": "",
          //   "VectorIndexPrefix": "smemory-",
          // },
        ],
      },
    },
    // ==================
    // ====== Misc ======
    // ==================
    "OpenApiEnabled": false
  },
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*"
}