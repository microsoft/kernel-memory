{
  "KernelMemory": {
    "Services": {
      "Onnx": {
        // Source: https://huggingface.co/microsoft/phi-4-onnx/tree/main
        "TextModelDir": "/tmp/onnx/phi-4-onnx",
        "MaxTokens": 16384
      },
      "AzureOpenAIEmbedding": {
        // "ApiKey" or "AzureIdentity"
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        // Optional when Auth == AzureIdentity. Leave it null to use the default.
        // in which case use this to change the client audience.
        "AzureIdentityAudience": null,
        "Endpoint": "https://<...>.openai.azure.com/",
        "APIKey": "",
        // Your Azure Deployment name
        "Deployment": "",
        // The max number of tokens supported by model deployed
        // See https://learn.microsoft.com/azure/ai-services/openai/concepts/models
        "MaxTokenTotal": 8191,
        // Which tokenizer to use to correctly measure the size of chunks.
        // Supported values: "p50k", "cl100k", "o200k". Leave it empty if unsure.
        // - Use p50k for the old text-davinci-003 models
        // - Use cl100k for the old gpt-3.4 and gpt-4 family, and for text embedding models
        // - Use o200k for the most recent gpt-4o family
        "Tokenizer": "cl100k",
        // The number of dimensions output embeddings should have.
        // Only supported in "text-embedding-3" and later models developed with
        // MRL, see https://arxiv.org/abs/2205.13147
        "EmbeddingDimensions": null,
        // How many embeddings to calculate in parallel. The max value depends on
        // the model and deployment in use.
        // See https://learn.microsoft.com/azure/ai-services/openai/reference#embeddings
        "MaxEmbeddingBatchSize": 1,
        // How many times to retry in case of throttling.
        "MaxRetries": 10,
        // Thumbprints of certificates that should be trusted for HTTPS requests when SSL policy errors are detected.
        // This should only be used for local development when using a proxy to call the OpenAI endpoints.
        "TrustedCertificateThumbprints": []
      }
    }
  }
}