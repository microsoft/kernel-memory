{
  "Logging": {
    "LogLevel": {
      "Default": "Trace",
      // Examples: how to handle logs differently by class
      //      "Microsoft.KernelMemory.Handlers.TextExtractionHandler": "Information",
      //      "Microsoft.KernelMemory.Handlers.TextPartitioningHandler": "Information",
      //      "Microsoft.KernelMemory.Handlers.GenerateEmbeddingsHandler": "Information",
      //      "Microsoft.KernelMemory.Handlers.SaveEmbeddingsHandler": "Information",
      //      "Microsoft.KernelMemory.DocumentStorage.AzureBlobs": "Information",
      //      "Microsoft.KernelMemory.Pipeline.Queue.AzureQueues": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "KernelMemory": {
    "Services": {
      "LlamaSharp": {
        // path to file, e.g. "llama-2-7b-chat.Q6_K.gguf"
        "ModelPath": "",
        // Max number of tokens supported by the model
        "MaxTokenTotal": 4096
        // Optional parameters
        // "GpuLayerCount": 32,
        // "Seed": 1337,
      },
      "AzureOpenAIEmbedding": {
        // "ApiKey" or "AzureIdentity"
        // AzureIdentity: use automatic AAD authentication mechanism. You can test locally
        //   using the env vars AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET.
        "Auth": "AzureIdentity",
        "Endpoint": "https://<...>.openai.azure.com/",
        "APIKey": "",
        "Deployment": "",
        // The max number of tokens supported by model deployed
        // See https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models
        "MaxTokenTotal": 8191
      },
      "OpenAI": {
        // Name of the model used to generate text (text completion or chat completion)
        "TextModel": "gpt-3.5-turbo-16k",
        // The max number of tokens supported by the text model.
        "TextModelMaxTokenTotal": 16384,
        // What type of text generation, by default autodetect using the model name.
        // Possible values: "Auto", "TextCompletion", "Chat"
        "TextGenerationType": "Auto",
        // Name of the model used to generate text embeddings
        "EmbeddingModel": "text-embedding-ada-002",
        // The max number of tokens supported by the embedding model
        // See https://platform.openai.com/docs/guides/embeddings/what-are-embeddings
        "EmbeddingModelMaxTokenTotal": 8191,
        // OpenAI API Key
        "APIKey": "",
        // OpenAI Organization ID (usually empty, unless you have multiple accounts on different orgs)
        "OrgId": "",
        // Endpoint to use. By default the system uses 'https://api.openai.com/v1'.
        // Change this to use proxies or services compatible with OpenAI HTTP protocol like LM Studio.
        "Endpoint": "",
        // How many times to retry in case of throttling
        "MaxRetries": 10
      }
    }
  }
}