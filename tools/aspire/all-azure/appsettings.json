{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning",
      "Aspire.Hosting.Dcp": "Warning"
    }
  },
  "KernelMemory": {
    "Services": {
      "AzureAIContentSafety": {
        // "ApiKey" or "AzureIdentity". For other options see <AzureAIContentSafetyConfig>.
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   When the service is on sovereign clouds you can use the AZURE_AUTHORITY_HOST env var to
        //   change the authority host. See https://learn.microsoft.com/dotnet/api/overview/azure/identity-readme
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        "Endpoint": "https://<...>",
        "APIKey": "",
        "GlobalSafetyThreshold": 0.0,
        "IgnoredWords": []
      },
      "AzureAISearch": {
        // "ApiKey" or "AzureIdentity". For other options see <AzureAISearchConfig>.
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   When the service is on sovereign clouds you can use the AZURE_AUTHORITY_HOST env var to
        //   set the authority host. See https://learn.microsoft.com/dotnet/api/overview/azure/identity-readme
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        "Endpoint": "https://<...>",
        "APIKey": "",
        // Hybrid search is not enabled by default. Note that when using hybrid search
        // relevance scores are different, usually lower, than when using just vector search
        "UseHybridSearch": false,
        // Helps improve relevance score consistency for search services with multiple replicas by
        // attempting to route a given request to the same replica for that session. Use this when
        // favoring consistent scoring over lower latency. Can adversely affect performance.
        //
        // Whether to use sticky sessions, which can help getting more consistent results.
        // When using sticky sessions, a best-effort attempt will be made to target the same replica set.
        // Be wary that reusing the same replica repeatedly can interfere with the load balancing of
        // the requests across replicas and adversely affect the performance of the search service.
        //
        // See https://learn.microsoft.com/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-07-01&tabs=HTTP#request-body
        "UseStickySessions": false
      },
      "AzureAIDocIntel": {
        // "APIKey" or "AzureIdentity".
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   When the service is on sovereign clouds you can use the AZURE_AUTHORITY_HOST env var to
        //   set the authority host. See https://learn.microsoft.com/dotnet/api/overview/azure/identity-readme
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        // Required when Auth == APIKey
        "APIKey": "",
        "Endpoint": ""
      },
      "AzureBlobs": {
        // "ConnectionString" or "AzureIdentity". For other options see <AzureBlobConfig>.
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   When the service is on sovereign clouds you can use the AZURE_AUTHORITY_HOST env var to
        //   set the authority host. See https://learn.microsoft.com/dotnet/api/overview/azure/identity-readme
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        // Azure Storage account name, required when using AzureIdentity auth
        // Note: you can use an env var 'KernelMemory__Services__AzureBlobs__Account' to set this
        "Account": "",
        // Container where to create directories and upload files
        "Container": "smemory",
        // Required when Auth == ConnectionString
        // Note: you can use an env var 'KernelMemory__Services__AzureBlobs__ConnectionString' to set this
        "ConnectionString": "",
        // Setting used only for country clouds
        "EndpointSuffix": "core.windows.net"
      },
      "AzureOpenAIEmbedding": {
        // "ApiKey" or "AzureIdentity"
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        // When the service is on sovereign clouds the AZURE_AUTHORITY_HOST env var might not work,
        // in which case use this setting to change the client audience. See:
        // - https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/README.md
        // - https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/src/Custom/AzureOpenAIAudience.cs
        "AzureOpenAIAudience": null,
        "Endpoint": "https://<...>.openai.azure.com/",
        "APIKey": "",
        // Your Azure Deployment name
        "Deployment": "",
        // The max number of tokens supported by model deployed
        // See https://learn.microsoft.com/azure/ai-services/openai/concepts/models
        "MaxTokenTotal": 8191,
        // Which tokenizer to use to correctly measure the size of chunks.
        // Supported values: "p50k", "cl100k", "o200k". Leave it empty if unsure.
        // - Use p50k for the old text-davinci-003 models
        // - Use cl100k for the old gpt-3.4 and gpt-4 family, and for text embedding models
        // - Use o200k for the most recent gpt-4o family
        "Tokenizer": "cl100k",
        // The number of dimensions output embeddings should have.
        // Only supported in "text-embedding-3" and later models developed with
        // MRL, see https://arxiv.org/abs/2205.13147
        "EmbeddingDimensions": null,
        // How many embeddings to calculate in parallel. The max value depends on
        // the model and deployment in use.
        // See https://learn.microsoft.com/azure/ai-services/openai/reference#embeddings
        "MaxEmbeddingBatchSize": 1,
        // How many times to retry in case of throttling.
        "MaxRetries": 10,
        // Thumbprints of certificates that should be trusted for HTTPS requests when SSL policy errors are detected.
        // This should only be used for local development when using a proxy to call the OpenAI endpoints.
        "TrustedCertificateThumbprints": []
      },
      "AzureOpenAIText": {
        // "ApiKey" or "AzureIdentity"
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        // When the service is on sovereign clouds the AZURE_AUTHORITY_HOST env var might not work,
        // in which case use this setting to change the client audience. See:
        // - https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/README.md
        // - https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/src/Custom/AzureOpenAIAudience.cs
        "AzureOpenAIAudience": null,
        "Endpoint": "https://<...>.openai.azure.com/",
        "APIKey": "",
        "Deployment": "",
        // The max number of tokens supported by model deployed
        // See https://learn.microsoft.com/azure/ai-services/openai/concepts/models
        "MaxTokenTotal": 16384,
        // Which tokenizer to use to correctly measure the size of chunks.
        // Supported values: "p50k", "cl100k", "o200k". Leave it empty if unsure.
        // - Use p50k for the old text-davinci-003 models
        // - Use cl100k for the old gpt-3.4 and gpt-4 family, and for text embedding models
        // - Use o200k for the most recent gpt-4o family
        "Tokenizer": "o200k",
        // "ChatCompletion" or "TextCompletion"
        "APIType": "ChatCompletion",
        // How many times to retry in case of throttling.
        "MaxRetries": 10,
        // Thumbprints of certificates that should be trusted for HTTPS requests when SSL policy errors are detected.
        // This should only be used for local development when using a proxy to call the OpenAI endpoints.
        "TrustedCertificateThumbprints": []
      },
      "AzureQueues": {
        // "ConnectionString" or "AzureIdentity". For other options see <AzureQueueConfig>.
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   When the service is on sovereign clouds you can use the AZURE_AUTHORITY_HOST env var to
        //   set the authority host. See https://learn.microsoft.com/dotnet/api/overview/azure/identity-readme
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        // Azure Storage account name, required when using AzureIdentity auth
        // Note: you can use an env var 'KernelMemory__Services__AzureQueue__Account' to set this
        "Account": "",
        // Required when Auth == ConnectionString
        // Note: you can use an env var 'KernelMemory__Services__AzureQueue__ConnectionString' to set this
        "ConnectionString": "",
        // Setting used only for country clouds
        "EndpointSuffix": "core.windows.net",
        // How often to check if there are new messages
        "PollDelayMsecs": 100,
        // How many messages to fetch at a time
        "FetchBatchSize": 3,
        // How long to lock messages once fetched. Azure Queue default is 30 secs
        "FetchLockSeconds": 300,
        // How many times to dequeue a messages and process before moving it to a poison queue
        "MaxRetriesBeforePoisonQueue": 20,
        // Suffix used for the poison queues.
        "PoisonQueueSuffix": "-poison"
      }
    }
  }
}
