{
  "KernelMemory": {
    "ServiceAuthorization": {
      "Endpoint": "http://127.0.0.1:9001/",
      "AccessKey": ""
    },
    "Services": {
      "AzureAISearch": {
        // "ApiKey" or "AzureIdentity". For other options see <AzureAISearchConfig>.
        // AzureIdentity: use automatic Entra (AAD) authentication mechanism.
        //   When the service is on sovereign clouds you can use the AZURE_AUTHORITY_HOST env var to
        //   set the authority host. See https://learn.microsoft.com/dotnet/api/overview/azure/identity-readme
        //   You can test locally using the AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars.
        "Auth": "AzureIdentity",
        "Endpoint": "https://<...>",
        "APIKey": "",
        "UseHybridSearch": false,
        "UseStickySessions": true
      },
      "LlamaSharp": {
        "TextModel": {
          // path to file, e.g. "llama-2-7b-chat.Q6_K.gguf"
          "ModelPath": "",
          // Max number of tokens supported by the model
          "MaxTokenTotal": 4096
          // Optional parameters
          // "GpuLayerCount": 32,
        },
        "EmbeddingModel": {
          // path to file, e.g. "nomic-embed-text-v1.5.Q8_0.gguf"
          "ModelPath": "",
          // Max number of tokens supported by the model
          "MaxTokenTotal": 4096
          // Optional parameters
          // "GpuLayerCount": 32,
        }
      },
      "MongoDbAtlas": {
        "ConnectionString": "mongodb://localhost:27017/?directConnection=true&serverSelectionTimeoutMS=2000",
        "DatabaseName": "TestKernelMemory"
      },
      "OpenAI": {
        // Name of the model used to generate text (text completion or chat completion)
        "TextModel": "gpt-4o-mini",
        // The max number of tokens supported by the text model.
        "TextModelMaxTokenTotal": 16384,
        // What type of text generation, by default autodetect using the model name.
        // Possible values: "Auto", "TextCompletion", "Chat"
        "TextGenerationType": "Auto",
        // Name of the model used to generate text embeddings
        "EmbeddingModel": "text-embedding-ada-002",
        // The max number of tokens supported by the embedding model
        // See https://platform.openai.com/docs/guides/embeddings/what-are-embeddings
        "EmbeddingModelMaxTokenTotal": 8191,
        // OpenAI API Key
        "APIKey": "",
        // OpenAI Organization ID (usually empty, unless you have multiple accounts on different orgs)
        "OrgId": "",
        // Endpoint to use. By default the system uses 'https://api.openai.com/v1'.
        // Change this to use proxies or services compatible with OpenAI HTTP protocol like LM Studio.
        "Endpoint": "",
        // How many times to retry in case of throttling
        "MaxRetries": 10,
        // The number of dimensions output embeddings should have.
        // Only supported in "text-embedding-3" and later models developed with
        // MRL, see https://arxiv.org/abs/2205.13147
        "EmbeddingDimensions": null,
        // How many embeddings to calculate in parallel.
        // See https://platform.openai.com/docs/api-reference/embeddings/create
        "MaxEmbeddingBatchSize": 100
      },
      "Postgres": {
        // Postgres instance connection string
        "ConnectionString": "Host=localhost;Port=5432;Username=public;Password=;Database=public",
        // Mandatory prefix to add to the name of table managed by KM,
        // e.g. to exclude other tables in the same schema.
        "TableNamePrefix": "tests-"
      },
      "Qdrant": {
        "Endpoint": "http://127.0.0.1:6333",
        "APIKey": ""
      },
      "Redis": {
        // Redis connection string, e.g. "localhost:6379,password=..."
        "ConnectionString": "localhost:6379",
        // List of tags that clients will use to filter memories. When using Redis,
        // the list of tags must be configured, for data to be saved correctly.
        "Tags": {
          "type": ",",
          "user": ",",
          "ext": ","
        }
      },
      "SimpleVectorDb": {
        // Options: "Disk" or "Volatile". Volatile data is lost after each execution.
        "StorageType": "Volatile",
        // Directory where files are stored.
        "Directory": "_vectors"
      }
    }
  },
  "Logging": {
    "LogLevel": {
      "Default": "Information"
    }
  }
}