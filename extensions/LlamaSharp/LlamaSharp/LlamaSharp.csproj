<Project Sdk="Microsoft.NET.Sdk">

    <PropertyGroup>
        <TargetFramework>net8.0</TargetFramework>
        <RollForward>LatestMajor</RollForward>
        <AssemblyName>Microsoft.KernelMemory.AI.LlamaSharp</AssemblyName>
        <RootNamespace>Microsoft.KernelMemory.AI.LlamaSharp</RootNamespace>
        <NoWarn>$(NoWarn);CA1724;CS1591;CA2208;</NoWarn>
    </PropertyGroup>

    <ItemGroup>
        <PackageReference Include="Microsoft.KernelMemory.Abstractions" Condition="'$(SolutionName)' != 'KernelMemoryDev'" />
        <ProjectReference Include="..\..\..\service\Abstractions\Abstractions.csproj" Condition="'$(SolutionName)' == 'KernelMemoryDev'" />
    </ItemGroup>

    <ItemGroup>
        <PackageReference Include="LLamaSharp" />
        <PackageReference Include="LLamaSharp.Backend.Cpu" />
        <PackageReference Include="LLamaSharp.Backend.Cuda12" />
        <PackageReference Include="System.Linq.Async" />
    </ItemGroup>

    <ItemGroup>
        <InternalsVisibleTo Include="Microsoft.UnitTests" />
    </ItemGroup>

    <Import Project="../../../code-analysis.props" />

    <Import Project="../../../nuget-package.props" />

    <PropertyGroup>
        <IsPackable>true</IsPackable>
        <PackageId>Microsoft.KernelMemory.AI.LlamaSharp</PackageId>
        <Product>LLama models connector for Kernel Memory</Product>
        <Description>Provide access to OpenAI LLM models in Kernel Memory to generate text</Description>
        <PackageTags>LLama, Plugin, Memory, RAG, Kernel Memory, Semantic Memory, Episodic Memory, Declarative Memory, AI, Artificial Intelligence, Embeddings, Vector DB, Vector Search, Memory DB, ETL</PackageTags>
    </PropertyGroup>

    <ItemGroup>
        <None Include="..\README.md" Link="README.md" Pack="true" PackagePath="." Visible="false" />
    </ItemGroup>

</Project>
